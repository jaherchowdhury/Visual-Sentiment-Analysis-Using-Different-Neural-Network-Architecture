{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03584438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adb32ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "input_size = (224, 224)\n",
    "batch_size = 42\n",
    "num_classes = 6  # Number of sentiment classes\n",
    "epochs = 50  # Adjust as needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967320bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69861ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess the dataset\n",
    "def preprocess_dataset(dataset_dir):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for emotion_label in os.listdir(dataset_dir):\n",
    "        emotion_dir = os.path.join(dataset_dir, emotion_label)\n",
    "        for image_file in os.listdir(emotion_dir):\n",
    "            image_path = os.path.join(emotion_dir, image_file)\n",
    "            image = load_img(image_path, target_size=input_size)\n",
    "            image = img_to_array(image)\n",
    "            \n",
    "            # Check if it's a color image (3 channels) or grayscale\n",
    "            if image.shape[-1] == 3:\n",
    "                data.append(image)\n",
    "            else:\n",
    "                # Apply histogram equalization to grayscale images\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                image = cv2.equalizeHist(image)\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
    "                data.append(image)\n",
    "\n",
    "            labels.append(emotion_label)\n",
    "    \n",
    "    label_encoder = LabelEncoder()\n",
    "    labels = label_encoder.fit_transform(labels)\n",
    "    return np.array(data), labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40bdfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the training and testing datasets\n",
    "train_dir = 'D:/Study/Digital Image Processing/Dataset/EmotionROI/training_testing_split/training'\n",
    "test_dir = 'D:/Study/Digital Image Processing/Dataset/EmotionROI/training_testing_split/testing'\n",
    "X_train, y_train = preprocess_dataset(train_dir)\n",
    "X_test, y_test = preprocess_dataset(test_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8411d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb19978f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Convert one-hot encoded labels to 1D labels\n",
    "y_train_labels = [np.argmax(label) for label in y_train]\n",
    "\n",
    "# Fit the LabelEncoder to the training labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_labels)\n",
    "\n",
    "# Save the fitted LabelEncoder\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e24f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a830cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "#from tensorflow.keras.constraints import max_norm\n",
    "# Load pre-trained models\n",
    "def create_transfer_model(base_model, dropout_rate=0.5,l2_penalty=0.01):\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2(l2_penalty))(x) #batch normalization\n",
    "    #Dense(1024, activation='relu', kernel_regularizer=l2(l2_penalty), kernel_constraint=max_norm(3))(x)\n",
    "    x = Dropout(dropout_rate)(x)  # Add dropout layer\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)#early_stopping with patience 5\n",
    "\n",
    "vgg_base = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=input_size + (3,))\n",
    "resnet_base = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=input_size + (3,))\n",
    "densenet_base = tf.keras.applications.DenseNet121(weights='imagenet', include_top=False, input_shape=input_size + (3,))\n",
    "\n",
    "\n",
    "vgg_model = create_transfer_model(vgg_base,l2_penalty=0.01)\n",
    "resnet_model = create_transfer_model(resnet_base,l2_penalty=0.01)\n",
    "densenet_model = create_transfer_model(densenet_base,l2_penalty=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a4022aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the models\n",
    "def compile_model(model):\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "compile_model(vgg_model)\n",
    "compile_model(resnet_model)\n",
    "compile_model(densenet_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa26e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generators for training and testing\n",
    "train_datagen = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
    "test_datagen = datagen.flow(X_test, y_test, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a7be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33/33 [==============================] - 746s 22s/step - loss: 8.6314 - accuracy: 0.1681 - val_loss: 8.2655 - val_accuracy: 0.1633\n",
      "Epoch 2/50\n",
      "33/33 [==============================] - 736s 22s/step - loss: 8.0551 - accuracy: 0.1551 - val_loss: 7.8256 - val_accuracy: 0.2172\n",
      "Epoch 3/50\n",
      "33/33 [==============================] - 738s 22s/step - loss: 7.6070 - accuracy: 0.1789 - val_loss: 7.3777 - val_accuracy: 0.2071\n",
      "Epoch 4/50\n",
      "33/33 [==============================] - 737s 22s/step - loss: 7.1598 - accuracy: 0.1941 - val_loss: 6.9388 - val_accuracy: 0.2205\n",
      "Epoch 5/50\n",
      "33/33 [==============================] - 737s 22s/step - loss: 6.7385 - accuracy: 0.1861 - val_loss: 6.5319 - val_accuracy: 0.2003\n",
      "Epoch 6/50\n",
      "33/33 [==============================] - 743s 23s/step - loss: 6.3388 - accuracy: 0.2078 - val_loss: 6.1184 - val_accuracy: 0.2071\n",
      "Epoch 7/50\n",
      "33/33 [==============================] - 739s 22s/step - loss: 5.9562 - accuracy: 0.2287 - val_loss: 5.7788 - val_accuracy: 0.2323\n",
      "Epoch 8/50\n",
      "33/33 [==============================] - 740s 22s/step - loss: 5.6113 - accuracy: 0.2172 - val_loss: 5.4423 - val_accuracy: 0.2205\n",
      "Epoch 9/50\n",
      "33/33 [==============================] - 736s 22s/step - loss: 5.2935 - accuracy: 0.2020 - val_loss: 5.1292 - val_accuracy: 0.2138\n",
      "Epoch 10/50\n",
      "33/33 [==============================] - 740s 22s/step - loss: 4.9871 - accuracy: 0.2165 - val_loss: 4.8326 - val_accuracy: 0.2172\n",
      "Epoch 11/50\n",
      "33/33 [==============================] - 738s 22s/step - loss: 4.7002 - accuracy: 0.1962 - val_loss: 4.5533 - val_accuracy: 0.2138\n",
      "Epoch 12/50\n",
      "33/33 [==============================] - 738s 22s/step - loss: 4.4210 - accuracy: 0.2179 - val_loss: 4.2745 - val_accuracy: 0.2340\n",
      "Epoch 13/50\n",
      "33/33 [==============================] - 735s 22s/step - loss: 4.1555 - accuracy: 0.2316 - val_loss: 4.0032 - val_accuracy: 0.2525\n",
      "Epoch 14/50\n",
      "33/33 [==============================] - 736s 22s/step - loss: 3.9178 - accuracy: 0.2605 - val_loss: 3.7963 - val_accuracy: 0.2946\n",
      "Epoch 15/50\n",
      "33/33 [==============================] - 732s 22s/step - loss: 3.7207 - accuracy: 0.2576 - val_loss: 3.6252 - val_accuracy: 0.2458\n",
      "Epoch 16/50\n",
      "33/33 [==============================] - 696s 21s/step - loss: 3.5303 - accuracy: 0.2626 - val_loss: 3.4237 - val_accuracy: 0.2694\n",
      "Epoch 17/50\n",
      "33/33 [==============================] - 716s 22s/step - loss: 3.3684 - accuracy: 0.2540 - val_loss: 3.2721 - val_accuracy: 0.2778\n",
      "Epoch 18/50\n",
      "33/33 [==============================] - 719s 22s/step - loss: 3.2047 - accuracy: 0.2814 - val_loss: 3.1523 - val_accuracy: 0.2912\n",
      "Epoch 19/50\n",
      "33/33 [==============================] - 723s 22s/step - loss: 3.0744 - accuracy: 0.2734 - val_loss: 3.0461 - val_accuracy: 0.2576\n",
      "Epoch 20/50\n",
      "33/33 [==============================] - 715s 22s/step - loss: 2.9370 - accuracy: 0.2691 - val_loss: 2.9055 - val_accuracy: 0.2508\n",
      "Epoch 21/50\n",
      "33/33 [==============================] - 719s 22s/step - loss: 2.8097 - accuracy: 0.2900 - val_loss: 2.8095 - val_accuracy: 0.2980\n",
      "Epoch 22/50\n",
      "33/33 [==============================] - 716s 22s/step - loss: 2.7218 - accuracy: 0.3066 - val_loss: 2.6954 - val_accuracy: 0.3030\n",
      "Epoch 23/50\n",
      "33/33 [==============================] - 723s 22s/step - loss: 2.6350 - accuracy: 0.3254 - val_loss: 2.6370 - val_accuracy: 0.2761\n",
      "Epoch 24/50\n",
      "33/33 [==============================] - 718s 22s/step - loss: 2.5534 - accuracy: 0.2879 - val_loss: 2.5363 - val_accuracy: 0.2828\n",
      "Epoch 25/50\n",
      "33/33 [==============================] - 719s 22s/step - loss: 2.4797 - accuracy: 0.3023 - val_loss: 2.4663 - val_accuracy: 0.2677\n",
      "Epoch 26/50\n",
      "33/33 [==============================] - 720s 22s/step - loss: 2.4028 - accuracy: 0.2763 - val_loss: 2.4000 - val_accuracy: 0.2946\n",
      "Epoch 27/50\n",
      "33/33 [==============================] - 720s 22s/step - loss: 2.2908 - accuracy: 0.3225 - val_loss: 2.3282 - val_accuracy: 0.3030\n",
      "Epoch 28/50\n",
      "33/33 [==============================] - 718s 22s/step - loss: 2.2667 - accuracy: 0.3290 - val_loss: 2.3099 - val_accuracy: 0.3165\n",
      "Epoch 29/50\n",
      "33/33 [==============================] - 719s 22s/step - loss: 2.2098 - accuracy: 0.3485 - val_loss: 2.2074 - val_accuracy: 0.3165\n",
      "Epoch 30/50\n",
      "33/33 [==============================] - 719s 22s/step - loss: 2.0985 - accuracy: 0.3716 - val_loss: 2.1774 - val_accuracy: 0.3098\n",
      "Epoch 31/50\n",
      "33/33 [==============================] - 726s 22s/step - loss: 2.0703 - accuracy: 0.3853 - val_loss: 2.1455 - val_accuracy: 0.3131\n",
      "Epoch 32/50\n",
      "33/33 [==============================] - 730s 22s/step - loss: 2.0082 - accuracy: 0.3896 - val_loss: 2.0928 - val_accuracy: 0.3434\n",
      "Epoch 33/50\n",
      "33/33 [==============================] - 733s 22s/step - loss: 1.9578 - accuracy: 0.3802 - val_loss: 2.0838 - val_accuracy: 0.3401\n",
      "Epoch 34/50\n",
      "30/33 [==========================>...] - ETA: 1:22 - loss: 1.8884 - accuracy: 0.4095"
     ]
    }
   ],
   "source": [
    "# Train the models\n",
    "vgg_history = vgg_model.fit(train_datagen, epochs=epochs, validation_data=test_datagen,callbacks=[early_stopping])\n",
    "resnet_history = resnet_model.fit(train_datagen,epochs=epochs, validation_data=test_datagen,callbacks=[early_stopping])\n",
    "densenet_history = densenet_model.fit(train_datagen, epochs=epochs, validation_data=test_datagen,callbacks=[early_stopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76749abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_train_loss = vgg_history.history['loss']\n",
    "vgg_val_loss = vgg_history.history['val_loss']\n",
    "vgg_train_acc = vgg_history.history['accuracy']\n",
    "vgg_val_acc = vgg_history.history['val_accuracy']\n",
    "\n",
    "resnet_train_loss = resnet_history.history['loss']\n",
    "resnet_val_loss = resnet_history.history['val_loss']\n",
    "resnet_train_acc = resnet_history.history['accuracy']\n",
    "resnet_val_acc = resnet_history.history['val_accuracy']\n",
    "\n",
    "densenet_train_loss = densenet_history.history['loss']\n",
    "densenet_val_loss = densenet_history.history['val_loss']\n",
    "densenet_train_acc = densenet_history.history['accuracy']\n",
    "densenet_val_acc = densenet_history.history['val_accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60894fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(vgg_train_loss, label='VGG19 Training Loss')\n",
    "plt.plot(vgg_val_loss, label='VGG19 Validation Loss')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('VGG19 Loss Over Time')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(vgg_train_acc, label='VGG19 Training Accuracy')\n",
    "plt.plot(vgg_val_acc, label='VGG19 Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('VGG19 Accuracy Over Time')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8faad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the VGG19 model\n",
    "vgg_model.save('vgg_emotion_model.h5')\n",
    "\n",
    "# Save the ResNet-50 model\n",
    "resnet_model.save('resnet_emotion_model.h5')\n",
    "\n",
    "# Save the DenseNet model\n",
    "densenet_model.save('densenet_emotion_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df346149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print accuracy for each model\n",
    "vgg_accuracy = vgg_history.history['accuracy'][-1]\n",
    "resnet_accuracy = resnet_history.history['accuracy'][-1]\n",
    "densenet_accuracy = densenet_history.history['accuracy'][-1]\n",
    "\n",
    "print(f'VGG19 Accuracy: {vgg_accuracy * 100:.2f}%')\n",
    "print(f'ResNet-50 Accuracy: {resnet_accuracy * 100:.2f}%')\n",
    "print(f'DenseNet Accuracy: {densenet_accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e17791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved models\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the VGG19 model\n",
    "vgg_model = load_model('vgg_emotion_model.h5')\n",
    "\n",
    "# Load the ResNet-50 model\n",
    "resnet_model = load_model('resnet_emotion_model.h5')\n",
    "\n",
    "# Load the DenseNet model\n",
    "densenet_model = load_model('densenet_emotion_model.h5')\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "vgg_evaluation = vgg_model.evaluate(X_test, y_test)\n",
    "resnet_evaluation = resnet_model.evaluate(X_test, y_test)\n",
    "densenet_evaluation = densenet_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"VGG19 Evaluation:\")\n",
    "print(\"Test Loss:\", vgg_evaluation[0])\n",
    "print(\"Test Accuracy:\", vgg_evaluation[1])\n",
    "\n",
    "print(\"\\nResNet-50 Evaluation:\")\n",
    "print(\"Test Loss:\", resnet_evaluation[0])\n",
    "print(\"Test Accuracy:\", resnet_evaluation[1])\n",
    "\n",
    "print(\"\\nDenseNet Evaluation:\")\n",
    "print(\"Test Loss:\", densenet_evaluation[0])\n",
    "print(\"Test Accuracy:\", densenet_evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_classes = encoder.classes_\n",
    "print(encoded_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f1ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a557f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3  # You can adjust the number of folds as needed\n",
    "vgg_accuracies = []\n",
    "resnet_accuracies = []\n",
    "densenet_accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7075df",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc111e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[test_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    vgg_model = create_transfer_model(vgg_base)\n",
    "    resnet_model = create_transfer_model(resnet_base)\n",
    "    densenet_model = create_transfer_model(densenet_base)\n",
    "    \n",
    "    compile_model(vgg_model)\n",
    "    compile_model(resnet_model)\n",
    "    compile_model(densenet_model)\n",
    "    \n",
    "    train_datagen = datagen.flow(X_train_fold, y_train_fold, batch_size=batch_size)\n",
    "    \n",
    "    vgg_history = vgg_model.fit(train_datagen, epochs=epochs, validation_data=(X_val_fold, y_val_fold),callbacks=[early_stopping])\n",
    "    resnet_history = resnet_model.fit(train_datagen, epochs=epochs, validation_data=(X_val_fold, y_val_fold),callbacks=[early_stopping])\n",
    "    densenet_history = densenet_model.fit(train_datagen, epochs=epochs, validation_data=(X_val_fold, y_val_fold),callbacks=[early_stopping])\n",
    "    \n",
    "    vgg_accuracies.append(vgg_history.history['val_accuracy'][-1])\n",
    "    resnet_accuracies.append(resnet_history.history['val_accuracy'][-1])\n",
    "    densenet_accuracies.append(densenet_history.history['val_accuracy'][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9315f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"VGG19 Cross-Validation Mean Accuracy: {np.mean(vgg_accuracies) * 100:.2f}%\")\n",
    "print(f\"VGG19 Cross-Validation Accuracy Std. Deviation: {np.std(vgg_accuracies) * 100:.2f}%\")\n",
    "\n",
    "print(f\"ResNet-50 Cross-Validation Mean Accuracy: {np.mean(resnet_accuracies) * 100:.2f}%\")\n",
    "print(f\"ResNet-50 Cross-Validation Accuracy Std. Deviation: {np.std(resnet_accuracies) * 100:.2f}%\")\n",
    "\n",
    "print(f\"DenseNet Cross-Validation Mean Accuracy: {np.mean(densenet_accuracies) * 100:.2f}%\")\n",
    "print(f\"DenseNet Cross-Validation Accuracy Std. Deviation: {np.std(densenet_accuracies) * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79595abb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f10a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
